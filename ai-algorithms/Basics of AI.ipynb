{
 "cells":[
  {
   "cell_type":"markdown",
   "source":[
    "# Basics of AI MOOC by Reaktor and Helsinki Uni\n",
    "In this notebook, I worked on the exercises for the Basics of AI free MOOC by Reaktor and Helsinki University. If you want to take the course, you can find it at https:\/\/buildingai.elementsofai.com\n",
    "## Exercise 1: Advanced\n",
    "In this exercise, you had to recursively iterate all the possible port combinations starting from Panama (PAN). Note: This solution isn't a direct answer as it uses a dash instead of a space to separate the routes. However, I like that presentation more.\n",
    "\n",
    "### TODO\n",
    "Use the let's plot geocode library and see if the routes could be plotted on a map"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"euStIzJdHeYgiKWOueon3d",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "portnames = [\"PAN\", \"AMS\", \"CAS\", \"NYC\", \"HEL\"]\n",
    " \n",
    "def permutations(route, ports):\n",
    "    if len(ports) <= 0:\n",
    "        print('-'.join([portnames[i] for i in route]))\n",
    "        return\n",
    "    for port in ports:\n",
    "        subroute = route.copy()\n",
    "        subroute.append(port)\n",
    "        subports = ports.copy()\n",
    "        subports.remove(port)\n",
    "        permutations(subroute, subports)\n",
    "\n",
    "# this will start the recursion with 0 as the first stop\n",
    "permutations([0], list(range(1, len(portnames))))"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "PAN-AMS-CAS-NYC-HEL\n",
      "PAN-AMS-CAS-HEL-NYC\n",
      "PAN-AMS-NYC-CAS-HEL\n",
      "PAN-AMS-NYC-HEL-CAS\n",
      "PAN-AMS-HEL-CAS-NYC\n",
      "PAN-AMS-HEL-NYC-CAS\n",
      "PAN-CAS-AMS-NYC-HEL\n",
      "PAN-CAS-AMS-HEL-NYC\n",
      "PAN-CAS-NYC-AMS-HEL\n",
      "PAN-CAS-NYC-HEL-AMS\n",
      "PAN-CAS-HEL-AMS-NYC\n",
      "PAN-CAS-HEL-NYC-AMS\n",
      "PAN-NYC-AMS-CAS-HEL\n",
      "PAN-NYC-AMS-HEL-CAS\n",
      "PAN-NYC-CAS-AMS-HEL\n",
      "PAN-NYC-CAS-HEL-AMS\n",
      "PAN-NYC-HEL-AMS-CAS\n",
      "PAN-NYC-HEL-CAS-AMS\n",
      "PAN-HEL-AMS-CAS-NYC\n",
      "PAN-HEL-AMS-NYC-CAS\n",
      "PAN-HEL-CAS-AMS-NYC\n",
      "PAN-HEL-CAS-NYC-AMS\n",
      "PAN-HEL-NYC-AMS-CAS\n",
      "PAN-HEL-NYC-CAS-AMS\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"CyoWxcEzeReJBkpKsi9H66",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Exercise 2: Advanced\n",
    "This exercise expanded on Exercise 1 by adding an emission table and solving which route combo emits the least amount of CO2. As in the first exercise, I opted to use a dash as to me it illustrates a route better.\n",
    "\n",
    "### TODO\n",
    "If geocode plotting works in Exercise 1, add it here too."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"uuIPOGcdiy3hJJXF5oDxTs",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "portnames = [\"PAN\", \"AMS\", \"CAS\", \"NYC\", \"HEL\"]\n",
    "\n",
    "# https:\/\/sea-distances.org\/\n",
    "# nautical miles converted to km\n",
    "\n",
    "D = [\n",
    "        [0,8943,8019,3652,10545],\n",
    "        [8943,0,2619,6317,2078],\n",
    "        [8019,2619,0,5836,4939],\n",
    "        [3652,6317,5836,0,7825],\n",
    "        [10545,2078,4939,7825,0]\n",
    "    ]\n",
    "\n",
    "# https:\/\/timeforchange.org\/co2-emissions-shipping-goods\n",
    "# assume 20g per km per metric ton (of pineapples)\n",
    "\n",
    "co2 = 0.020\n",
    "\n",
    "# DATA BLOCK ENDS\n",
    "\n",
    "# these variables are initialised to nonsensical values\n",
    "# your program should determine the correct values for them\n",
    "smallest = 1000000\n",
    "bestroute = [0, 0, 0, 0, 0]\n",
    "\n",
    "def permutations(route, ports):\n",
    "    global smallest, bestroute\n",
    "    if len(ports) <= 0:\n",
    "        #print('-'.join([portnames[i] for i in route]))\n",
    "        emissions = 0\n",
    "        for port in range(0,len(route)-1):\n",
    "            emissions += D[route[port]][route[port+1]]\n",
    "        emissions *= co2\n",
    "        if emissions < smallest:\n",
    "            smallest = emissions\n",
    "            bestroute = route\n",
    "        return\n",
    "    for port in ports:\n",
    "        subroute = route.copy()\n",
    "        subroute.append(port)\n",
    "        subports = ports.copy()\n",
    "        subports.remove(port)\n",
    "        permutations(subroute, subports)\n",
    "\n",
    "def main():\n",
    "    # this will start the recursion \n",
    "    permutations([0], list(range(1, len(portnames))))\n",
    "\n",
    "    # print the best route and its emissions\n",
    "    print('-'.join([portnames[i] for i in bestroute]) + \" %.1f kg\" % smallest)\n",
    "\n",
    "main()"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "PAN-NYC-CAS-AMS-HEL 283.7 kg\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"WPmjHRxhgTCk0bwMXJfN89",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Exercise 3: Advanced\n",
    "This exercise explored the hill climbing algorithm. The solution might crash in the edge cases, but it did pass so whatever (read: too laze to iterate and find out for sure). The plot draws the \"mountains\" and marks the found peak."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"0rYHf4JA9HUwjWFD7oPLFB",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from lets_plot import *\n",
    "\n",
    "import math\n",
    "import random             \t# just for generating random mountains                                 \t \n",
    "\n",
    "# generate random mountains                                                                               \t \n",
    "\n",
    "w = [.05, random.random()\/3, random.random()\/3]\n",
    "h = [1.+math.sin(1+x\/.6)*w[0]+math.sin(-.3+x\/9.)*w[1]+math.sin(-.2+x\/30.)*w[2] for x in range(100)]\n",
    "\n",
    "def climb(x, h):\n",
    "    # keep climbing until we've found a summit\n",
    "    summit = False\n",
    "\n",
    "    # edit here\n",
    "    while not summit:\n",
    "        summit = True         # stop unless there's a way up\n",
    "        rightbound = min(x + 5, len(h))\n",
    "        leftbound = max(x - 5, 0)\n",
    "        for step in range(0, rightbound):\n",
    "            if h[step] > h[x]:\n",
    "                x = step        # right is higher, go there\n",
    "                summit = False    # and keep going\n",
    "        for step in range(0, leftbound, -1):\n",
    "            if h[step] > h[x]:\n",
    "                x = step\n",
    "                summit = False\n",
    "    return x\n",
    "\n",
    "def main(h):\n",
    "    # start at a random place                                                                                  \t \n",
    "    x0 = random.randint(1, 98)\n",
    "    x = climb(x0, h)\n",
    "    plot = ggplot(dict(X=list(range(0,100)), Y=h), aes('X', 'Y')) + geom_line() + geom_point(x=x, y=h[x], size=10, shape=9, color='red')\n",
    "    return plot\n",
    "    #return x0, x\n",
    "\n",
    "main(h)"
   ],
   "execution_count":null,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<html lang=\"en\">\n",
       "   <head>\n",
       "       <script type=\"text\/javascript\" data-lets-plot-script=\"library\" src=\"https:\/\/cdnjs.cloudflare.com\/ajax\/libs\/lets-plot\/2.0.2\/lets-plot.min.js\"><\/script>\n",
       "   <\/head>\n",
       "   <body>\n",
       "          <div id=\"nkpT7D\"><\/div>\n",
       "   <script type=\"text\/javascript\" data-lets-plot-script=\"plot\">\n",
       "       var plotSpec={\n",
       "'data':{\n",
       "'X':[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0,51.0,52.0,53.0,54.0,55.0,56.0,57.0,58.0,59.0,60.0,61.0,62.0,63.0,64.0,65.0,66.0,67.0,68.0,69.0,70.0,71.0,72.0,73.0,74.0,75.0,76.0,77.0,78.0,79.0,80.0,81.0,82.0,83.0,84.0,85.0,86.0,87.0,88.0,89.0,90.0,91.0,92.0,93.0,94.0,95.0,96.0,97.0,98.0,99.0],\n",
       "'Y':[1.0063674848913864,0.9945699410727313,0.9327537539075893,0.9727774720355516,1.0434224785293802,1.0063764563263806,0.9592493948075898,1.0215795484098549,1.0727869112394908,1.0163362215277334,0.9912111258865297,1.0672658906675103,1.0920760397194693,1.0249073475520365,1.0259284350171103,1.1051628270019451,1.1004839184247228,1.0328760728396742,1.0604262068487236,1.1318710217270656,1.098932842960547,1.0412659603005863,1.0919105922538637,1.145762612239406,1.0899318438172783,1.0511704486703328,1.118144637035165,1.147175924344707,1.0771589891678897,1.0635295380269802,1.137697864000664,1.1382805679961399,1.064831582781436,1.0788887465173371,1.150041475692807,1.1226425682179566,1.0569678216019902,1.0971893069674712,1.155491013898295,1.1045698939021142,1.056665680328978,1.1176396917833327,1.1550252805890575,1.0883545485742914,1.0655252316173078,1.1387086898803427,1.1500292301023955,1.0775423120194156,1.0833186423035392,1.1582604521740598,1.1420164443788923,1.0743531082579543,1.1079711059610138,1.173825453506585,1.1323831502997919,1.0793457837060523,1.1358628898758965,1.1829731542577147,1.1222323316400507,1.091376454614683,1.1624067227882457,1.1837279954157003,1.1122869734030945,1.107847762800681,1.1828058472871879,1.1749555392566373,1.102890484138023,1.1251966561300226,1.1928650241256789,1.1566438661937417,1.0940744670039313,1.1395293405982099,1.189715705969136,1.1300181594486747,1.0856628441207503,1.147290316773695,1.172329741829607,1.0974523381132988,1.0773787543094628,1.145851123586869,1.1417312727404652,1.0621765224373665,1.0689264761632014,1.133923026049395,1.1008678997585752,1.027816885954757,1.0600328017502847,1.1117323302750255,1.0541607894136442,0.997837988975957,1.0504473573339106,1.0809405466629327,1.006808838805475,0.9749803248861355,1.0399153495291922,1.044336153051722,0.9639645705029801,0.9607925978978349,1.0281455071905048,1.0053623029772283]\n",
       "},\n",
       "'mapping':{\n",
       "'x':\"X\",\n",
       "'y':\"Y\"\n",
       "},\n",
       "'data_meta':{\n",
       "},\n",
       "'kind':\"plot\",\n",
       "'scales':[],\n",
       "'layers':[{\n",
       "'geom':\"line\",\n",
       "'mapping':{\n",
       "},\n",
       "'data_meta':{\n",
       "},\n",
       "'data':{\n",
       "}\n",
       "},{\n",
       "'geom':\"point\",\n",
       "'mapping':{\n",
       "},\n",
       "'data_meta':{\n",
       "},\n",
       "'x':68,\n",
       "'y':1.1928650241256789,\n",
       "'size':10,\n",
       "'shape':9,\n",
       "'color':\"red\",\n",
       "'data':{\n",
       "}\n",
       "}]\n",
       "};\n",
       "       var plotContainer = document.getElementById(\"nkpT7D\");\n",
       "       LetsPlot.buildPlotFromProcessedSpecs(plotSpec, -1, -1, plotContainer);\n",
       "   <\/script>\n",
       "   <\/body>\n",
       "<\/html>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"S0sJqlcynGQdd7zGyUM6Dl",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Exercise 4: Advanced\n",
    "This exercise was teaching random in Python. Probably overcomplicated the solution a bit but just goes to show there are multiple ways to skin a cat. And a dog. And a bat."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"tDW9yptKICZ3aOzXwRG0VS",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import random\n",
    "\n",
    "def main():\n",
    "    probs = [0.8, 0.9, 1.0]\n",
    "    animals = [\"dogs\", \"cats\", \"bats\"]\n",
    "    prob = random.random()\n",
    "    favorite = \"\"\n",
    "    if prob < probs[0]:\n",
    "        favorite = animals[0]\n",
    "    elif prob >= probs[0] and prob < probs[1]:\n",
    "        favorite = animals[1]\n",
    "    elif prob >= probs[1] and prob < probs[2]:\n",
    "        favorite = animals[2]\n",
    "    else:\n",
    "        favorite = \"coding errors\"\n",
    "    print(\"I love \" + favorite) \n",
    "\n",
    "main()"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "I love dogs\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"pSenq7NwTT9yg6vmG0q1aZ",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Exercise 5: Advanced\n",
    "This exercise implements simulated annealing. The return function had some challenges with working in Safari importing Numpy. The instructions weren't also super clear if you actually need to output something. ~~Might need to test on a different browser.~~ Tested on Vivaldi, and got kind of a cryptic assertion.\n",
    "\n",
    "Turns out that as the mathematical definition for a probability means clamping between 0 and 1, the test actually ran also with OLD being smaller than NEW, which resulted in a like a 270 percent probability. I just fixed it with a simple clamp (editor's note: Why doesn't Python have something as simple as clamp? coder's note: Did you check numpy?), which might or might not be the correct way."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"J2WgXedfPhwEolz0Y8Zl0e",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def clamp(num, min_value, max_value):\n",
    "   return max(min(num, max_value), min_value)\n",
    "\n",
    "def accept_prob(S_old, S_new, T):\n",
    "    # this is the acceptance \"probability\" in the greedy hill-climbing method\n",
    "    # where new solutions are accepted if and only if they are better\n",
    "    # than the old one.\n",
    "    # change it to be the acceptance probability in simulated annealing\n",
    "    return clamp(np.exp(-(S_old - S_new)\/T), 0.0, 1.0)\n",
    "\n",
    "# the above function will be used as follows. this is shown just for\n",
    "# your information; you don't have to change anything here\n",
    "def accept(S_old, S_new, T):\n",
    "    if random.random() < accept_prob(S_old, S_new, T):\n",
    "        print(True)\n",
    "    else:\n",
    "        print(False)\n",
    "accept(150, 140, 15)"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "True\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"HY0wYoPbSxLnklthX8CAXc",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Exercise 6: Advanced\n",
    "The last exercise combined all of the above to try improve the hill climbing algorithm. This challenge had the same problem as the previous one, so no-go to run on Safari. ~~Maybe try with a different browser on the site later.~~ Tried with Vivaldi. Was able to test and submit (after updating the accept_prob with clamp from the previous).\n",
    "\n",
    "The plot draws all the tracks and renders succesful ones in green. If the function is working, you should see more green than grey.\n",
    "\n",
    "### TODO\n",
    "+ Figure out how to plot the peaks like in the last hillclimbing. The dataframes are a bit different this time around.\n",
    "+ Numpy apparently is easy to get to overflow. Figure out how to get the exp to play nice and not overflowing."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"Kkz5t2BFSJXHNbDZoSxNS6",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "N = 100     # size of the problem is N x N                                      \n",
    "steps = 3000    # total number of iterations                                        \n",
    "tracks = 50\n",
    "\n",
    "def clamp(num, min_value, max_value):\n",
    "   return max(min(num, max_value), min_value)\n",
    "\n",
    "def accept_prob(S_old, S_new, T):\n",
    "    # this is the acceptance \"probability\" in the greedy hill-climbing method\n",
    "    # where new solutions are accepted if and only if they are better\n",
    "    # than the old one.\n",
    "    # change it to be the acceptance probability in simulated annealing\n",
    "    if T <= 0:\n",
    "        return 0\n",
    "    return clamp(np.exp(-(S_old - S_new)\/T), 0.0, 1.0)\n",
    "\n",
    "# generate a landscape with multiple local optima                                          \n",
    "def generator(x, y, x0=0.0, y0=0.0):\n",
    "    return np.sin((x\/N-x0)*np.pi)+np.sin((y\/N-y0)*np.pi)+\\\n",
    "        .07*np.cos(12*(x\/N-x0)*np.pi)+.07*np.cos(12*(y\/N-y0)*np.pi)\n",
    "\n",
    "x0 = np.random.random() - 0.5\n",
    "y0 = np.random.random() - 0.5\n",
    "h = np.fromfunction(np.vectorize(generator), (N, N), x0=x0, y0=y0, dtype=int)\n",
    "peak_x, peak_y = np.unravel_index(np.argmax(h), h.shape)\n",
    "\n",
    "# starting points                                                               \n",
    "x = np.random.randint(0, N, tracks)\n",
    "y = np.random.randint(0, N, tracks)\n",
    "\n",
    "def main():\n",
    "    global x\n",
    "    global y\n",
    "\n",
    "    for step in range(steps):\n",
    "        # add a temperature schedule here\n",
    "        T = max(0, ((steps - step)\/steps)**3-.005)\n",
    "        # update solutions on each search track                                     \n",
    "        for i in range(tracks):\n",
    "            # try a new solution near the current one                               \n",
    "            x_new = np.random.randint(max(0, x[i]-2), min(N, x[i]+2+1))\n",
    "            y_new = np.random.randint(max(0, y[i]-2), min(N, y[i]+2+1))\n",
    "            S_old = h[x[i], y[i]]\n",
    "            S_new = h[x_new, y_new]\n",
    "\n",
    "            # change this to use simulated annealing\n",
    "            if random.random() < accept_prob(S_old, S_new, T):\n",
    "                x[i], y[i] = x_new, y_new   # new solution is better, go there       \n",
    "            else:\n",
    "                pass                        # if the new solution is worse, do nothing\n",
    "\n",
    "    # Number of tracks found the peak\n",
    "    print(sum([x[j] == peak_x and y[j] == peak_y for j in range(tracks)]))\n",
    "    for j in range(tracks):\n",
    "        plotcolor=\"grey\"\n",
    "        if x[j] == peak_x and y[j] == peak_y:\n",
    "            plotcolor=\"green\"\n",
    "        plt.plot(list(range(0,100)), h[j], color=plotcolor)\n",
    "    plt.show()\n",
    "main()"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "39\n"
     ],
     "output_type":"stream"
    },
    {
     "data":{
      
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"Sua5Hae1fO8PsgagWrbMG4",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Exercise 7: Advanced\n",
    "This exercise was about coin flipping, checking times there's at least 5 heads (or tails whichever you want to view it), and checking the count is close to a certain value. As the before examples, the Basics of AI site doesn't like Numpy and Safari combo, so need to verify this in a different browser.\n",
    "\n",
    "### TODO\n",
    "Add a visualization for the coin flips."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"KNPazA3YkpZbQtKXI7tuNt",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import numpy as np\n",
    "\n",
    "def generate(p1):\n",
    "    # change this so that it generates 10000 random zeros and ones\n",
    "    # where the probability of one is p1\n",
    "    seq = np.random.choice([0,1], p=[1-p1, p1], size=10000)\n",
    "    return seq\n",
    "\n",
    "def count(seq):\n",
    "    five_ones = 0\n",
    "    ones = 0\n",
    "    for number in seq:\n",
    "        if number == 1:\n",
    "            ones += 1\n",
    "            if ones >= 5:\n",
    "                five_ones += 1\n",
    "        else:\n",
    "            ones = 0\n",
    "    return five_ones\n",
    "\n",
    "def main(p1):\n",
    "    seq = generate(p1)\n",
    "    return count(seq)\n",
    "\n",
    "print(main(2\/3))"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "1369\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"k4JqT4ra3Ssvtj7Er3POr3",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Exercise 8: Advanced\n",
    "This exercise was about probabilities, including Nordic fishermen and lottery."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"bxD9bTmTwkEGO5OGztC2GB",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "countries = ['Denmark', 'Finland', 'Iceland', 'Norway', 'Sweden']\n",
    "populations = [5615000, 5439000, 324000, 5080000, 9609000]\n",
    "male_fishers = [1822, 2575, 3400, 11291, 1731]\n",
    "female_fishers = [69, 77, 400, 320, 26] \n",
    "\n",
    "def guess(winner_gender):\n",
    "    if winner_gender == 'female':\n",
    "        fishers = female_fishers\n",
    "    else:\n",
    "        fishers = male_fishers\n",
    "\n",
    "    guess_country = None\n",
    "    biggest = 0.0\n",
    "    for country in range(0, len(countries)):\n",
    "        probability = fishers[country] \/ sum(fishers) * 100\n",
    "        if probability < biggest:\n",
    "            continue\n",
    "        biggest = probability\n",
    "        guess_country = countries[country]\n",
    "    return (guess_country, biggest)  \n",
    "\n",
    "def main():\n",
    "    country, fraction = guess(\"male\")\n",
    "    print(\"if the winner is male, my guess is he's from %s; probability %.2f%%\" % (country, fraction))\n",
    "    country, fraction = guess(\"female\")\n",
    "    print(\"if the winner is female, my guess is she's from %s; probability %.2f%%\" % (country, fraction))\n",
    "\n",
    "main()"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "if the winner is male, my guess is he's from Norway; probability 54.23%\n",
      "if the winner is female, my guess is she's from Iceland; probability 44.84%\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"K2vJemwedKtKZ3CzVCd94y",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Exercise 9: Advanced\n",
    "This exercise was social media blocking exercise based on the Bayes rule."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"FkEy2bChO4yhABaL0Zcc7w",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def bot8(pbot, p8_bot, p8_human):\n",
    "    pbot_8 = p8_bot * pbot \/ (p8_bot * pbot + p8_human * (1 - pbot))\n",
    "    print(pbot_8)\n",
    "\n",
    "# you can change these values to test your program with different values\n",
    "pbot = 0.1\n",
    "p8_bot = 0.8\n",
    "p8_human = 0.05\n",
    "\n",
    "bot8(pbot, p8_bot, p8_human)"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "0.64\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"ggH7hSslb74jNTLBBitr56",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Exercise 10: Advanced\n",
    "Exercise 10 was all about the naive Bayes.\n",
    "\n",
    "### TODO\n",
    "Add a visualization for the dice throws"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"BqDVk0epoQWrWOXcb5c4g3",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import numpy as np\n",
    "\n",
    "p1 = [1\/6, 1\/6, 1\/6, 1\/6, 1\/6, 1\/6]   # normal\n",
    "p2 = [0.1, 0.1, 0.1, 0.1, 0.1, 0.5]   # loaded\n",
    "\n",
    "def roll(loaded):\n",
    "    if loaded:\n",
    "        print(\"rolling a loaded die\")\n",
    "        p = p2\n",
    "    else:\n",
    "        print(\"rolling a normal die\")\n",
    "        p = p1\n",
    "\n",
    "    # roll the dice 10 times\n",
    "    # add 1 to get dice rolls from 1 to 6 instead of 0 to 5\n",
    "    sequence = np.random.choice(6, size=10, p=p) + 1 \n",
    "    for roll in sequence:\n",
    "        print(\"rolled %d\" % roll)\n",
    "        \n",
    "    return sequence\n",
    "\n",
    "def bayes(sequence):\n",
    "    odds = 1.0           # start with odds 1:1\n",
    "    for roll in sequence:\n",
    "        ratio = p2[roll-1]\/p1[roll-1]\n",
    "        odds *= ratio\n",
    "    if odds > 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "sequence = roll(True)\n",
    "if bayes(sequence):\n",
    "    print(\"I think loaded\")\n",
    "else:\n",
    "    print(\"I think normal\")"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "rolling a loaded die\n",
      "rolled 6\n",
      "rolled 6\n",
      "rolled 6\n",
      "rolled 4\n",
      "rolled 2\n",
      "rolled 1\n",
      "rolled 2\n",
      "rolled 1\n",
      "rolled 6\n",
      "rolled 3\n",
      "I think loaded\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"oJ1WEUkfKuMPKX9Us4C7ed",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Exercise 11: Advanced\n",
    "This excercise was about linear regression. Predicting prices for Finnish summer cottages. The usual Nordic things."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"vTDSfr743LwFHKcB0Dd38U",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# input values for three mökkis: size, size of sauna, distance to water, number of indoor bathrooms, \n",
    "# proximity of neighbors\n",
    "X = [[66, 5, 15, 2, 500], \n",
    "     [21, 3, 50, 1, 100], \n",
    "     [120, 15, 5, 2, 1200]]\n",
    "c = [3000, 200, -50, 5000, 100]    # coefficient values\n",
    "\n",
    "def predict(X, c):\n",
    "    for cabin in X:\n",
    "        price = 0\n",
    "        for index in range(0, len(c)):\n",
    "            price += c[index] * cabin[index]\n",
    "        print(price)\n",
    "\n",
    "predict(X, c)"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "258250\n",
      "76100\n",
      "492750\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"AUZT5iYdGW8QFuA4SiLKeh",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Exercise 12: Advanced\n",
    "In this exercise, a \"poor man's\" Least squares algorithm was tried out."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"9aRmRVMiEo71pKPOkbKoiK",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import numpy as np\n",
    "\n",
    "# data\n",
    "X = np.array([[66, 5, 15, 2, 500], \n",
    "              [21, 3, 50, 1, 100], \n",
    "              [120, 15, 5, 2, 1200]])\n",
    "y = np.array([250000, 60000, 525000])\n",
    "\n",
    "# alternative sets of coefficient values\n",
    "c = np.array([[3000, 200 , -50, 5000, 100], \n",
    "              [2000, -250, -100, 150, 250], \n",
    "              [3000, -100, -150, 0, 150]])   \n",
    "\n",
    "def find_best(X, y, c):\n",
    "    smallest_error = np.Inf\n",
    "    best_index = -1\n",
    "    current_index = 0\n",
    "    for coeff in c:\n",
    "        error = 0\n",
    "        for index in range(0, len(y)):\n",
    "            coeffed = coeff @ X[index]\n",
    "            diff = y[index] - coeffed\n",
    "            error += diff * diff\n",
    "        if error < smallest_error:\n",
    "            smallest_error = error\n",
    "            best_index = current_index\n",
    "        current_index += 1\n",
    "    print(\"the best set is set %d\" % best_index)\n",
    "\n",
    "\n",
    "find_best(X, y, c)"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "the best set is set 1\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"hXFdM1HlbY6ka8z04SQ4ID",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Exercise 13: Advanced\n",
    "This exercise added more data to showcase how prediction fails (in the expansion of the previous one the prediction didn't, due to math magic)."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"E8XpqtHctvJbenNrt1L2Ae",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import numpy as np\n",
    "from io import StringIO\n",
    "\n",
    "input_string = '''\n",
    "25 2 50 1 500 127900\n",
    "39 3 10 1 1000 222100\n",
    "13 2 13 1 1000 143750\n",
    "82 5 20 2 120 268000\n",
    "130 6 10 2 600 460700\n",
    "115 6 10 1 550 407000\n",
    "'''\n",
    "\n",
    "np.set_printoptions(precision=1)    # this just changes the output settings for easier reading\n",
    " \n",
    "def fit_model(input_file):\n",
    "    df = np.genfromtxt(input_file, skip_header=1)\n",
    "    x = df[:,0:-1]      # input data to the linear regression\n",
    "    y = df[:,-1]\n",
    "    c = np.linalg.lstsq(x, y, rcond=-1)[0]\n",
    "    print(c)\n",
    "    print(x @ c)\n",
    "\n",
    "# simulate reading a file\n",
    "input_file = StringIO(input_string)\n",
    "fit_model(input_file)"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "[2989.6  800.6  -44.8 3890.8   99.8]\n",
      "[127907.6 222269.8 143604.5 268017.6 460686.6 406959.9]\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"CAD7kQQI9mEwGlv5ttw21y",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Exercise 14: Advanced\n",
    "This one took a step towards machine learning, splitting training data and test data, while the previous used the same data for both."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"FgfI0eOecxptqMUYXgyfb6",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import numpy as np\n",
    "from io import StringIO\n",
    "\n",
    "train_string = '''\n",
    "25 2 50 1 500 127900\n",
    "39 3 10 1 1000 222100\n",
    "13 2 13 1 1000 143750\n",
    "82 5 20 2 120 268000\n",
    "130 6 10 2 600 460700\n",
    "115 6 10 1 550 407000\n",
    "'''\n",
    "\n",
    "test_string = '''\n",
    "36 3 15 1 850 196000\n",
    "75 5 18 2 540 290000\n",
    "'''\n",
    "\n",
    "def main():\n",
    "    np.set_printoptions(precision=1)    # this just changes the output settings for easier reading\n",
    "\n",
    "    # read in the training data and separate it to x_train and y_train\n",
    "    input_file = StringIO(train_string)\n",
    "    df = np.genfromtxt(input_file, skip_header=1)\n",
    "    x_train = df[:,0:-1]\n",
    "    y_train = df[:,-1]\n",
    "\n",
    "    # fit a linear regression model to the data and get the coefficients\n",
    "    c = np.linalg.lstsq(x_train, y_train, rcond=-1)[0]\n",
    "\n",
    "    # read in the test data and separate x_test from it\n",
    "    input_file = StringIO(test_string)\n",
    "    df = np.genfromtxt(input_file, skip_header=1)\n",
    "    x_test = df[:,0:-1]\n",
    "    #y_test = df[:,-1]\n",
    "\n",
    "    # print out the linear regression coefficients\n",
    "    print(c)\n",
    "\n",
    "    # this will print out the predicted prics for the two new cabins in the test data set\n",
    "    print(x_test @ c)\n",
    "\n",
    "\n",
    "main()"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "[2989.6  800.6  -44.8 3890.8   99.8]\n",
      "[198102.4 289108.3]\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"cvYUWTrZt3CMWpH9Md7zjO",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Exercise 15: Advanced\n",
    "This exercise moved on to nearest neighbor methods. The first one is calculating vector distances."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"ILR9EWEHwolYYtDKKSKDAS",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import numpy as np\n",
    "\n",
    "x_train = np.random.rand(10, 3)   # generate 10 random vectors of dimension 3\n",
    "x_test = np.random.rand(3)        # generate one more random vector of the same dimension\n",
    "\n",
    "def dist(a, b):\n",
    "    sum = 0\n",
    "    for ai, bi in zip(a, b):\n",
    "        sum = sum + (ai - bi)**2\n",
    "    return np.sqrt(sum)\n",
    "    \n",
    "def nearest(x_train, x_test):\n",
    "    nearest = -1\n",
    "    min_distance = np.Inf\n",
    "    # add a loop here that goes through all the vectors in x_train and finds the one that\n",
    "    # is nearest to x_test. return the index (between 0, ..., len(x_train)-1) of the nearest\n",
    "    # neighbor\n",
    "    for index in range(0, len(x_train)):\n",
    "        distance = dist(x_test, x_train[index])\n",
    "        if(distance < min_distance):\n",
    "            min_distance = distance\n",
    "            nearest = index\n",
    "    print(nearest)\n",
    "\n",
    "nearest(x_train, x_test)"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "8\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"6eE4PqcGZtkLC4CiJ2nrAj",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Exercise 16: Advanced\n",
    "The second part of doing nearest neighbor algorithms. This investigates k number of neighbors for classifications."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"y7oxmZCntDg3tp2jwQY9m5",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create random data with two classes\n",
    "X, Y = make_blobs(n_samples=16, n_features=2, centers=2, center_box=(-2, 2))\n",
    "\n",
    "# scale the data so that all values are between 0.0 and 1.0\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "# split two data points from the data as test data and\n",
    "# use the remaining n-2 points as the training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=2)\n",
    "\n",
    "# place-holder for the predicted classes\n",
    "y_predict = np.empty(len(y_test), dtype=np.int64)\n",
    "\n",
    "# produce line segments that connect the test data points\n",
    "# to the nearest neighbors for drawing the chart\n",
    "lines = []\n",
    "\n",
    "# distance function\n",
    "def dist(a, b):\n",
    "    sum = 0\n",
    "    for ai, bi in zip(a, b):\n",
    "        sum = sum + (ai - bi)**2\n",
    "    return np.sqrt(sum)\n",
    "\n",
    "\n",
    "def main(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    global y_predict\n",
    "    global lines\n",
    "\n",
    "    k = 3    # classify our test items based on the classes of 3 nearest neighbors\n",
    "    \n",
    "    # process each of the test data points\n",
    "    for i, test_item in enumerate(X_test):\n",
    "        # calculate the distances to all training points\n",
    "        distances = [dist(train_item, test_item) for train_item in X_train]\n",
    "\n",
    "        # add your code here\n",
    "        #nearest = np.argmin(distances)       # this just finds the nearest neighbour (so k=1)\n",
    "        sdistances = np.argsort(distances)\n",
    "        # create a line connecting the points for the chart\n",
    "        # you may change this to do the same for all the k nearest neigbhors if you like\n",
    "        # but it will not be checked in the tests\n",
    "        ylist = []\n",
    "        for index in range(0, 3):\n",
    "            lines.append(np.stack((test_item, X_train[sdistances[index]])))\n",
    "            ylist.append(y_train[sdistances[index]])\n",
    "        y_predict[i] = np.round(np.mean(ylist))\n",
    "    \n",
    "    print(y_predict)\n",
    "\n",
    "main(X_train, X_test, y_train, y_test)"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "[0 0]\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"xzNqdqex1xrOo6xVwzSORZ",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Exercise 17: Advanced\n",
    "Moving from numbers to words, this exercise was bag of words mixed with Manhattan distance. In essence, you were given the words already as numbers, so not really working with words. But since computers only know ones and zeros, all is well."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"OvHMADi2viyFVgyekrswi2",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import numpy as np\n",
    "\n",
    "data = [[1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
    "        [1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1],\n",
    "        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1],\n",
    "        [1, 1, 1, 0, 1, 3, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1]]\n",
    "\n",
    "def distance(row1, row2):\n",
    "    sum = 0\n",
    "    for index in range(0, len(row1)):\n",
    "        sum += abs(row1[index] - row2[index])\n",
    "    return sum\n",
    "    \n",
    "def find_nearest_pair(data):\n",
    "    N = len(data)\n",
    "    dist = np.empty((N, N), dtype=np.float)\n",
    "    outerrowindex = 0\n",
    "    for row in data:\n",
    "        innerrowindex = 0\n",
    "        for secondrow in data:\n",
    "            if innerrowindex == outerrowindex:\n",
    "                dist[outerrowindex, innerrowindex] = np.inf\n",
    "            else:\n",
    "                dist[outerrowindex, innerrowindex] = distance(row, secondrow)\n",
    "            innerrowindex += 1\n",
    "        outerrowindex += 1\n",
    "            \n",
    "    print(np.unravel_index(np.argmin(dist), dist.shape))\n",
    "\n",
    "find_nearest_pair(data)"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "(2, 3)\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"UAVFWaqxLzKwj4Eb7hLsEy",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Excercise 18: Advanced\n",
    "In this excercise, the simple bag of words is replaced with the tf-idf algorigthm. We also finally work with words themselves. Obviously, the words get converted to numbers for analyzing, but hey, at least we can say we are working with text (editor's note: Last excercise was the \"little piggy went to market\" if it wasn't clear from the 0s and 1s)"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"27Mm3b46oeLoMRGh9C8t4F",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import math\n",
    "import numpy as np\n",
    "\n",
    "text = '''Humpty Dumpty sat on a wall\n",
    "Humpty Dumpty had a great fall\n",
    "all the king's horses and all the king's men\n",
    "couldn't put Humpty together again'''\n",
    "\n",
    "def distance(a, b):\n",
    "    sum = 0\n",
    "    for ai, bi in zip(a, b):\n",
    "        sum = sum + (ai - bi)**2\n",
    "    return np.sqrt(sum)\n",
    "\n",
    "def main(text):\n",
    "    # tasks your code should perform:\n",
    "\n",
    "    # 1. split the text into words, and get a list of unique words that appear in it\n",
    "    # a short one-liner to separate the text into sentences (with words lower-cased to make words equal \n",
    "    # despite casing) can be done with \n",
    "    # docs = [line.lower().split() for line in text.split('\\n')]\n",
    "    docs = [line.lower().split() for line in text.split('\\n')]\n",
    "    docdictionary = {}\n",
    "    linedictionaries = []\n",
    "    # 2. go over each unique word and calculate its term frequency, and its document frequency\n",
    "    for line in docs:\n",
    "        linedictionary = {}\n",
    "        for word in line:\n",
    "            if word in linedictionary.keys():\n",
    "                linedictionary[word] += 1\n",
    "            else:\n",
    "                linedictionary[word] = 1\n",
    "            if word in docdictionary.keys():\n",
    "                docdictionary[word] += 1\n",
    "            else:\n",
    "                docdictionary[word] = 1\n",
    "        linedictionaries.append(linedictionary)\n",
    "    # 3. after you have your term frequencies and document frequencies, go over each line in the text and \n",
    "    # calculate its TF-IDF representation, which will be a vector\n",
    "    tfidf_vector = []\n",
    "    lineindex = 0\n",
    "    for line in docs:\n",
    "        line_vector = []\n",
    "        for word in line:\n",
    "            line_vector.append(linedictionaries[lineindex][word] * math.log(1\/docdictionary[word]))\n",
    "        tfidf_vector.append(line_vector)\n",
    "        lineindex += 1\n",
    "    # 4. after you have calculated the TF-IDF representations for each line in the text, you need to\n",
    "    # calculate the distances between each line to find which are the closest.\n",
    "    #N = len(tfidf_vector)\n",
    "    outerrow = []\n",
    "    outerrowindex = 0\n",
    "    for row in tfidf_vector:\n",
    "        innerrowindex = 0\n",
    "        innerrow = []\n",
    "        for secondrow in tfidf_vector:\n",
    "            if innerrowindex == outerrowindex:\n",
    "                innerrow.append(np.inf)\n",
    "            else:\n",
    "                innerrow.append(distance(row, secondrow))\n",
    "            innerrowindex += 1\n",
    "        outerrow.append(innerrow)\n",
    "        outerrowindex += 1\n",
    "    dist = np.stack(outerrow)        \n",
    "    print(np.unravel_index(np.argmin(dist), dist.shape))\n",
    "\n",
    "main(text)"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "(0, 1)\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"PNuFZ6GvOVdcd72E8s9WZi",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Exercise 19: Advanced\n",
    "This exercise investigates combating overfitting."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"4h8p8wa4PjPwq9aAPVPcON",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# do not edit this\n",
    "# create fake data\n",
    "x, y = make_moons(\n",
    "    n_samples=500,  # the number of observations\n",
    "    random_state=42,\n",
    "    noise=0.3\n",
    ")\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Create a classifier and fit it to our data\n",
    "k_values = [1, 250, 42, 100]\n",
    "for value in k_values:\n",
    "    print(\"Testing with k:\", value)\n",
    "    knn = KNeighborsClassifier(n_neighbors=value)\n",
    "    knn.fit(x_train, y_train)\n",
    "    training_accuracy = knn.score(x_train, y_train)\n",
    "    testing_accuracy = knn.score(x_test, y_test)\n",
    "    print(\"training accuracy: %f\" % training_accuracy)\n",
    "    print(\"testing accuracy: %f\" % testing_accuracy)"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Testing with k: 1\n",
      "training accuracy: 1.000000\n",
      "testing accuracy: 0.860606\n",
      "Testing with k: 250\n",
      "training accuracy: 0.767164\n",
      "testing accuracy: 0.812121\n",
      "Testing with k: 42\n",
      "training accuracy: 0.925373\n",
      "testing accuracy: 0.909091\n",
      "Testing with k: 100\n",
      "training accuracy: 0.880597\n",
      "testing accuracy: 0.890909\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"RSElntPVpuDO2cHKmZoZEo",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Excercise 20: Advanced\n",
    "Exercises from here on out were not required for completion certificate, but figured I'll do them anyways. First topic covered logistical regression, an expansion to the linear regression covered earlier."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"R4cH5L2gl4DQFtUeCc3Wnr",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import math\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([4, 3, 0])\n",
    "c1 = np.array([-.5, .1, .08])\n",
    "c2 = np.array([-.2, .2, .31])\n",
    "c3 = np.array([.5, -.1, 2.53])\n",
    "\n",
    "def linear(x, c):\n",
    "    sum = 0\n",
    "    for index in range(0, len(c)):\n",
    "        sum += c[index] * x[index]\n",
    "    return sum\n",
    "    \n",
    "def sigmoid(z):\n",
    "    # add your implementation of the sigmoid function here\n",
    "    sigmoid = 1\/(1+math.exp(-z))\n",
    "    return sigmoid\n",
    "\n",
    "# calculate the output of the sigmoid for x with all three coefficients\n",
    "s = sigmoid(linear(x, c1))\n",
    "print(s)\n",
    "s = sigmoid(linear(x, c2))\n",
    "print(s)\n",
    "s = sigmoid(linear(x, c3))\n",
    "print(s)"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "0.1544652650835347\n",
      "0.45016600268752216\n",
      "0.8455347349164652\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"Pq7PnyFc4DCKvMDK1CPM9D",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Excercise 21: Advanced\n",
    "After going through all of the above, we jump to neural networks. Which in essence are just what we did above, but networked in a certain way. Time to do some passes. Like good old Raimo Helminen."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"3AENgF1LtkqVGt4i0nhDkA",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import numpy as np\n",
    "\n",
    "w0 = np.array([[ 1.19627687e+01,  2.60163283e-01],\n",
    "               [ 4.48832507e-01,  4.00666119e-01],\n",
    "                   [-2.75768443e-01,  3.43724167e-01],\n",
    "                   [ 2.29138536e+01,  3.91783025e-01],\n",
    "                   [-1.22397711e-02, -1.03029800e+00]])\n",
    "\n",
    "w1 = np.array([[11.5631751 , 11.87043684],\n",
    "                   [-0.85735419,  0.27114237]])\n",
    "\n",
    "w2 = np.array([[11.04122165],\n",
    "                   [10.44637262]])\n",
    "\n",
    "b0 = np.array([-4.21310294, -0.52664488])\n",
    "b1 = np.array([-4.84067881, -4.53335139])\n",
    "b2 = np.array([-7.52942418])\n",
    "\n",
    "x = np.array([[111, 13, 12, 1, 161],\n",
    "                 [125, 13, 66, 1, 468],\n",
    "                 [46, 6, 127, 2, 961],\n",
    "                 [80, 9, 80, 2, 816],\n",
    "                 [33, 10, 18, 2, 297],\n",
    "                 [85, 9, 111, 3, 601],\n",
    "                 [24, 10, 105, 2, 1072],\n",
    "                 [31, 4, 66, 1, 417],\n",
    "                 [56, 3, 60, 1, 36],\n",
    "                 [49, 3, 147, 2, 179]])\n",
    "y = np.array([335800., 379100., 118950., 247200., 107950., 266550.,  75850.,\n",
    "                93300., 170650., 149000.])\n",
    "\n",
    "\n",
    "def hidden_activation(z):\n",
    "    return np.max(z, 0)\n",
    "\n",
    "def output_activation(z):\n",
    "    return z\n",
    "\n",
    "x_test = [[82, 2, 65, 3, 516]]\n",
    "for item in x_test:\n",
    "    h1_in = np.dot(item, w0) + b0 # this calculates the linear combination of inputs and weights\n",
    "    h1_out = hidden_activation(h1_in) # apply activation function\n",
    "    h2_in = np.dot(h1_out, w1) + b1\n",
    "    h2_out = hidden_activation(h2_in)\n",
    "    out_in = np.dot(h2_out, w2) + b2\n",
    "    out = output_activation(out_in)\n",
    "    print(out)"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "[257136.4]\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"SHIrlMLAmTlrZNrk15LOyS",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Conclusion\n",
    "And that's all she wrote.\n",
    "\n",
    "### TODO\n",
    "Revisit the above and add plotting where it seems fun."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"i2XgrE88TkfZFDl82BBiYc",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "version":1,
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    
   ]
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}